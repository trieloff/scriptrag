name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  UV_VERSION: "0.5.12"
  NODE_VERSION: "20"

permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: write

jobs:
  # Check if Python files were changed to determine if tests should run
  changes:
    name: Detect Changed Files
    runs-on: ubuntu-latest
    outputs:
      python: ${{ steps.filter.outputs.python }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            python:
              - '**/*.py'
              - 'pyproject.toml'
              - 'setup.py'
              - 'setup.cfg'
              - 'requirements*.txt'

  lint:
    name: Lint & Code Quality
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Install dependencies
        run: make install

      - name: Run linting checks
        run: make lint

  type-check:
    name: Type Checking
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Install dependencies
        run: make install

      - name: Run MyPy
        run: make type-check

  security:
    name: Security Checks
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Install dependencies
        run: make install

      - name: Run security checks
        run: make security

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: .bandit-report.json

      - name: Upload Safety report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: safety-report
          path: .safety-report.json

  test-unix:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    needs: changes
    if: needs.changes.outputs.python == 'true'
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.12", "3.13"]
        exclude:
          # Reduce matrix for faster CI
          - os: macos-latest
            python-version: "3.13"

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: uv-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/uv.lock', '**/pyproject.toml') }}
          restore-keys: |
            uv-${{ runner.os }}-py${{ matrix.python-version }}-

      - name: Install dependencies
        run: make install
        shell: bash

      - name: Run tests with pytest
        run: make test

      - name: Surface failing tests
        uses: pmeier/pytest-results-action@main
        if: always()
        with:
          path: junit.xml
          summary: true
          display-options: fEsX
          fail-on-empty: true
          title: "Test Results (${{ matrix.os }}, Python ${{ matrix.python-version }})"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: junit.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  test-windows:
    name: Test Python ${{ matrix.python-version }} on Windows
    runs-on: windows-latest
    needs: [changes, test-unix]
    if: needs.changes.outputs.python == 'true'
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: uv-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/uv.lock', '**/pyproject.toml') }}
          restore-keys: |
            uv-${{ runner.os }}-py${{ matrix.python-version }}-

      - name: Install dependencies
        run: make install
        shell: bash

      - name: Windows Debug Info
        shell: pwsh
        run: |
          Write-Host "=== Windows Debug Information ==="
          Write-Host "Temp directory: $env:TEMP"
          Write-Host "Number of CPUs: $env:NUMBER_OF_PROCESSORS"
          Write-Host "Available memory:"
          Get-CimInstance Win32_OperatingSystem | Select-Object TotalVisibleMemorySize, FreePhysicalMemory
          Write-Host "Python location:"
          Get-Command python
          Write-Host "UV location:"
          Get-Command uv
          Write-Host "Current directory contents:"
          Get-ChildItem -Force
          Write-Host "================================="

      - name: Run tests with pytest
        run: |
          echo "Starting pytest at $(date)"
          echo "Python version: $(python --version)"
          echo "OS: windows-latest"
          echo "Runner: ${{ runner.os }}"
          make test
          echo "Finished pytest at $(date)"

      - name: Surface failing tests
        uses: pmeier/pytest-results-action@main
        if: always()
        with:
          path: junit.xml
          summary: true
          display-options: fEsX
          fail-on-empty: true
          title: "Test Results (Windows, Python ${{ matrix.python-version }})"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-windows-latest-py${{ matrix.python-version }}
          path: junit.xml

  docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    needs: changes
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Install dependencies and build documentation
        run: |
          make install
          make docs

      - name: Upload documentation
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: site/

  build:
    name: Build Distribution
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Build distribution
        run: make build

      - name: Check distribution
        run: make check-dist

      - name: Upload distribution
        uses: actions/upload-artifact@v4
        with:
          name: distribution
          path: dist/

  pre-commit:
    name: Pre-commit Hooks
    runs-on: ubuntu-latest
    needs: changes
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install markdownlint-cli
        run: npm install -g markdownlint-cli

      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [changes, lint, type-check, test-unix]
    if: needs.changes.outputs.python == 'true'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Install dependencies
        run: make install

      - name: Run integration tests
        run: make test PYTEST_ARGS="-m integration"
        env:
          SCRIPTRAG_LLM_ENDPOINT: ${{ secrets.SCRIPTRAG_LLM_ENDPOINT }}
          SCRIPTRAG_LLM_API_KEY: ${{ secrets.SCRIPTRAG_LLM_API_KEY }}
          SCRIPTRAG_LLM_DEFAULT_MODEL: ${{ secrets.SCRIPTRAG_LLM_DEFAULT_MODEL || 'default' }}
          SCRIPTRAG_ENVIRONMENT: testing

      - name: Surface failing integration tests
        uses: pmeier/pytest-results-action@main
        if: always()
        with:
          path: junit.xml
          summary: true
          display-options: fEsX
          fail-on-empty: true
          title: "Integration Test Results"

  all-checks:
    name: All Checks Passed
    runs-on: ubuntu-latest
    needs: [changes, lint, type-check, security, test-unix, test-windows, docs, build, pre-commit]
    if: always()
    outputs:
      all_passed: ${{ steps.check.outputs.all_passed }}
    steps:
      - name: Check if all jobs passed
        id: check
        run: |
          # If no Python changes, automatically pass
          if [[ "${{ needs.changes.outputs.python }}" != "true" ]]; then
            echo "No Python files changed - skipping checks"
            echo "all_passed=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check for failures only if Python files were changed
          if [[ "${{ contains(needs.*.result, 'failure') }}" == "true" ]]; then
            echo "One or more jobs failed"
            echo "all_passed=false" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "All jobs passed successfully"
            echo "all_passed=true" >> $GITHUB_OUTPUT
          fi

  notify-terry:
    name: Notify Terry on Failure
    runs-on: ubuntu-latest
    needs: [changes, lint, type-check, security, test-unix, test-windows, docs, build, pre-commit]
    if: |
      failure() &&
      github.event_name == 'pull_request' &&
      contains(github.event.pull_request.body, 'terragonlabs.com/task') &&
      needs.changes.outputs.python == 'true'
    permissions:
      pull-requests: write
    steps:
      - name: Extract Terry Task ID
        id: extract-task
        run: |
          PR_BODY='${{ github.event.pull_request.body }}'
          TASK_URL=$(echo "$PR_BODY" | \
            grep -oE 'https://www\.terragonlabs\.com/task/[a-f0-9-]+' | head -1)
          if [ -n "$TASK_URL" ]; then
            TASK_ID=$(echo "$TASK_URL" | \
              grep -oE '[a-f0-9-]+-[a-f0-9-]+-[a-f0-9-]+-[a-f0-9-]+-[a-f0-9-]+$')
            echo "task_id=$TASK_ID" >> $GITHUB_OUTPUT
            echo "task_url=$TASK_URL" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
          fi

      - name: Comment on PR with failure notification
        if: steps.extract-task.outputs.found == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const taskUrl = '${{ steps.extract-task.outputs.task_url }}';
            const jobStatuses = {
              lint: '${{ needs.lint.result }}',
              typeCheck: '${{ needs.type-check.result }}',
              security: '${{ needs.security.result }}',
              testUnix: '${{ needs.test-unix.result }}',
              testWindows: '${{ needs.test-windows.result }}',
              docs: '${{ needs.docs.result }}',
              build: '${{ needs.build.result }}',
              preCommit: '${{ needs.pre-commit.result }}'
            };

            const failedJobs = Object.entries(jobStatuses)
              .filter(([_, status]) => status === 'failure')
              .map(([job, _]) => job);

            // Only notify if there are actual CI failures (not external job failures)
            if (failedJobs.length === 0) {
              console.log('No CI jobs failed that are under Terragon Labs control');
              return;
            }

            const runUrl = `https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}`;

            const comment = [
              '@terragon-labs The CI build has failed for this PR.',
              '',
              `Failed checks: ${failedJobs.join(', ')}`,
              '',
              'Please investigate the failures and fix the issues:',
              `- [View full CI run](${runUrl})`,
              `- [Terry Task](${taskUrl})`,
              '',
              `You can use \`terry pull ${{ steps.extract-task.outputs.task_id }}\` to continue working on this task.`,
              '',
              '_Note: This notification only includes CI checks that are part of the core build process. External checks like Claude Code Review are excluded._'
            ].join('\n');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });

  # Call the reusable post-CI workflow
  post-ci-actions:
    name: Post-CI Actions
    needs: [all-checks]
    if: |
      github.event_name == 'pull_request' &&
      needs.all-checks.outputs.all_passed == 'true' &&
      needs.all-checks.result == 'success'
    uses: ./.github/workflows/post-ci.yml
    with:
      pr_number: "${{ github.event.pull_request.number }}"
      pr_head_ref: "${{ github.event.pull_request.head.ref }}"
      pr_head_sha: "${{ github.event.pull_request.head.sha }}"
      trigger_claude_review: true
    secrets:
      GH_TOKEN_FOR_CLAUDE: ${{ secrets.GH_TOKEN_FOR_CLAUDE }}
      CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

  vibe-badge:
    name: Generate Vibe Badge
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: write
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Generate Vibe Badge
        uses: trieloff/vibe-coded-badge-action@main
        continue-on-error: true
